{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "29b9bd1d-766f-4422-ad96-de0accc1ce58"
    }
   },
   "source": [
    "# Lab 2 - Fully Connected Feedforward Network with MNIST\n",
    "# Model Overview\n",
    "\n",
    "In this lab, we will train a fully connected feedforward network on MNIST data. \n",
    "\n",
    "The lab comprises two parts. During the first part, the instructor will walk you through the code to define, train, and evaluate the initial version of FCNN model. In the second part you will compete with other students to improve the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our fully connected feedforward network - a.k.a multi-layer perceptron - will be relatively simple with 2 hidden layers (`num_hidden_layers`). The number of nodes in the hidden layer being a parameter specified by `hidden_layers_dim`. The figure below illustrates the entire model we will use in this tutorial in the context of MNIST data.\n",
    "\n",
    "![model-mlp](http://cntk.ai/jup/cntk103c_MNIST_MLP.png)\n",
    "\n",
    "In this and the following labs we will demonstrate the use of the Functional API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Walkthrough\n",
    "## Initialize environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "138d1a78-02e2-4bd6-a20e-07b83f303563"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cntk as C\n",
    "from IPython.display import Image\n",
    "\n",
    "# Ensure we always get the same amount of randomness\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reading\n",
    "\n",
    "In this lab we are using the MNIST data pre-processed to follow CNTK CTF format. \n",
    "\n",
    "\n",
    "    |labels 0 0 0 0 0 0 0 1 0 0 |features 0 0 0 0 ... \n",
    "                                                  (784 integers each representing a pixel)\n",
    "                                                 \n",
    "\n",
    "Each line in the file contains two key-value pairs, also refered as streams. The `labels` stream is the one-hot encoded representation of a digit 0-9. The `features` stream is a 784 vector of 0-255 integers representing 28 x 28 pixel grayscale image.\n",
    "\n",
    "Our dataset includes three files: the training file with 50,000 images, the validation file with 10,000 images, and the testing file with 10,000 images.\n",
    "\n",
    "To read/sample the files, we define a `create_reader` function that configures and returns the CNTK MinibatchSource object.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_file = \"../Data/MNIST_train.txt\"\n",
    "validation_file = \"../Data/MNIST_validate.txt\"\n",
    "test_file = '../Data/MNIST_test.txt'\n",
    "\n",
    "# Read a CTF formatted text (as mentioned above) using the CTF deserializer from a file\n",
    "def create_reader(path, is_training, input_dim, num_label_classes):\n",
    "    return C.io.MinibatchSource(C.io.CTFDeserializer(path, C.io.StreamDefs(\n",
    "        labels = C.io.StreamDef(field='labels', shape=num_label_classes),\n",
    "        features   = C.io.StreamDef(field='features', shape=input_dim)\n",
    "    )), randomize = is_training, max_sweeps = C.io.INFINITELY_REPEAT if is_training else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network definition and training\n",
    "\n",
    "### Define the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a fully connected feedforward classification network factory with sigmoid neurons in the hidden layers\n",
    "def create_fcnn_network(input_dim, num_hidden_layers, hidden_layer_dim, num_output_classes):\n",
    "    # Create inputs \n",
    "    features = C.input_variable(input_dim)\n",
    "\n",
    "    # Scale the input features\n",
    "    feature_scale = 1.0/256.0\n",
    "    features_norm = C.element_times(feature_scale, features) \n",
    "    \n",
    "    with C.layers.default_options(init = C.layers.glorot_uniform(), activation = C.ops.sigmoid):\n",
    "        network_template = C.layers.Sequential([\n",
    "            C.layers.For(range(num_hidden_layers), lambda i: C.layers.Dense(hidden_layer_dim, name = 'hidden' + str(i))),\n",
    "            C.layers.Dense(num_output_classes, activation = None, name='classify')])\n",
    "    \n",
    "    z = network_template(features_norm)\n",
    "    return z\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and visualize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_dim = 784\n",
    "num_output_classes = 10\n",
    "num_hidden_layers = 2\n",
    "hidden_layer_dim = 400\n",
    "\n",
    "z = create_fcnn_network(input_dim, num_hidden_layers, hidden_layer_dim, num_output_classes)\n",
    "C.logging.graph.plot(z, \"graph.png\")\n",
    "Image(\"graph.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure training \n",
    "#### Configure a trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_trainer(network, labels):\n",
    "    ## Define loss and metric\n",
    "    loss = C.cross_entropy_with_softmax(network, labels)\n",
    "    metric = C.classification_error(network, labels)\n",
    "\n",
    "    # Create an SGD learner\n",
    "    lr_schedule = C.learning_rate_schedule(0.2, C.UnitType.minibatch)\n",
    "    learner = C.sgd(network.parameters, lr_schedule)\n",
    "\n",
    "    # Create a progress printing helper\n",
    "    progress_printer = C.logging.ProgressPrinter()\n",
    "\n",
    "    # Create a trainer\n",
    "    return C.Trainer(network, (loss, metric), [learner], [progress_printer])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure a training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_validate(network, training_file, validation_file, mb_schedule, epoch_size, num_epochs):\n",
    "\n",
    "    # Extract input and output dimensions\n",
    "    input_dim = network.arguments[0].shape[0]\n",
    "    num_output_classes = network.outputs[0].shape[0]\n",
    "    \n",
    "    # Create the training and validation data set readers\n",
    "    reader_train = create_reader(training_file, True, input_dim, num_output_classes)\n",
    "    reader_validate = create_reader(validation_file, False, input_dim, num_output_classes)\n",
    "\n",
    "     # Define mappings from reader streams to network and ground truth inputs\n",
    "    features = network.arguments[0]\n",
    "    labels = C.input_variable(num_output_classes, is_sparse=True)\n",
    "   \n",
    "    input_map_training = {\n",
    "        features: reader_train.streams.features,\n",
    "        labels: reader_train.streams.labels\n",
    "    }\n",
    "\n",
    "    # Define mappings from reader streams to network inputs\n",
    "    input_map_validation = {\n",
    "        features: reader_validate.streams.features,\n",
    "        labels: reader_validate.streams.labels\n",
    "    }\n",
    "    \n",
    "    # Create a trainer\n",
    "    trainer = create_trainer(network, labels)\n",
    "\n",
    "    # Set up cross-validation configuration\n",
    "    cv_config = C.CrossValidationConfig(minibatch_source=reader_validate,\n",
    "                                        model_inputs_to_streams = input_map_validation,\n",
    "                                        frequency=None)\n",
    "\n",
    "    # Create a training session\n",
    "    training_sess = C.training_session(trainer=trainer,\n",
    "                                 mb_source=reader_train,\n",
    "                                 mb_size=mb_schedule,\n",
    "                                 model_inputs_to_streams=input_map_training,\n",
    "                                 progress_frequency=epoch_size,\n",
    "                                 max_samples=epoch_size * num_epochs,\n",
    "                                 cv_config=cv_config \n",
    "                                )\n",
    "\n",
    "    training_sess.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "epoch_size = 6400\n",
    "num_epochs = 100\n",
    "mb_schedule = 64\n",
    "\n",
    "train_and_validate(z, training_file, validation_file, mb_schedule, epoch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hackathon\n",
    "\n",
    "Try to improve the performance of the model. \n",
    "\n",
    "Hints:\n",
    "- Try different activation functions in hidden layers\n",
    "- Play with the learning rate, minibatch size and the number of sweeps\n",
    "- You can look at regularization - check `l1_regularization` and `l2_regularization` hyper parameters of the `sgd` learner\n",
    "- Try different optimization algorithms\n",
    "\n",
    "## Final testing\n",
    "\n",
    "\n",
    "DON'T CHEAT. DON'T USE MNIST_test.txt FOR MODEL TRAINING AND SELECTION. DON'T EXECUTE THE BELOW CELL TILL YOU ARE READY FOR THE FINAL TEST\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def final_evaluation(network, test_file):\n",
    "    \n",
    "    # Extract input and output dimensions\n",
    "    input_dim = network.arguments[0].shape[0]\n",
    "    num_output_classes = network.outputs[0].shape[0]\n",
    "    \n",
    "    # Create the test data set readers\n",
    "    reader = create_reader(test_file, False,  input_dim, num_output_classes)\n",
    "\n",
    "     # Define mappings from reader streams to network and ground truth inputs\n",
    "    features = network.arguments[0]\n",
    "    labels = C.input_variable(num_output_classes, is_sparse=True)\n",
    "   \n",
    "    input_map = {\n",
    "        features: reader.streams.features,\n",
    "        labels: reader.streams.labels\n",
    "    }\n",
    "   \n",
    "    metric = C.classification_error(network, labels)\n",
    "    \n",
    "    evaluator = C.Evaluator(metric, [C.logging.ProgressPrinter()])\n",
    "    \n",
    "    minibatch_size = 1024\n",
    "    data = reader.next_minibatch(minibatch_size, input_map=input_map)\n",
    "    while bool(data):\n",
    "        evaluator.test_minibatch(data)\n",
    "        data = reader.next_minibatch(minibatch_size, input_map=input_map)\n",
    "    evaluator.summarize_test_progress()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "final_evaluation(z, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
